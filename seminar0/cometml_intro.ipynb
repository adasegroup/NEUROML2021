{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComentML: crash course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the ML platform allowing data scientists and teams to track, compare, explain and optimize experiments and models. \n",
    "\n",
    "https://www.comet.ml/site/\n",
    "\n",
    "Benefits:\n",
    "- easy to share the experiment\n",
    "- easy to reproduse other expreiments\n",
    "- easy to get fancy plots\n",
    "- you can attach the `html` page to your paper results, and it is going to be a standard of sharing of the research in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/kondratevakate/pytorch-dummy-project/7796b3978a114d51a799ad948c87421a\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     mean_fit_time [4]           : (0.000997447967529297, 0.0017934322357177734)\n",
      "COMET INFO:     mean_score_time [4]         : (0.0007973670959472656, 0.0009967327117919923)\n",
      "COMET INFO:     mean_test_score [4]         : (0.9666666666666666, 0.9800000000000001)\n",
      "COMET INFO:     param_C [4]                 : (1, 10)\n",
      "COMET INFO:     param_kernel [4]            : rbf\n",
      "COMET INFO:     rank_test_score [4]         : (1, 4)\n",
      "COMET INFO:     split0_test_score [4]       : (0.9666666666666667, 1.0)\n",
      "COMET INFO:     split1_test_score [4]       : (0.9666666666666667, 1.0)\n",
      "COMET INFO:     split2_test_score [4]       : (0.9, 0.9666666666666667)\n",
      "COMET INFO:     split3_test_score [4]       : (0.9333333333333333, 0.9666666666666667)\n",
      "COMET INFO:     split4_test_score [4]       : 1.0\n",
      "COMET INFO:     std_fit_time [4]            : (4.90933901833868e-07, 0.0004885585982569543)\n",
      "COMET INFO:     std_score_time [4]          : (3.2340669551493016e-07, 0.00039952035705644566)\n",
      "COMET INFO:     std_test_score [4]          : (0.016329931618554516, 0.038873012632301994)\n",
      "COMET INFO:     test_accuracy               : 1\n",
      "COMET INFO:     train_batch_accuracy [1202] : (array(0, dtype=int64), array(1, dtype=int64))\n",
      "COMET INFO:     train_loss [121]            : (0.011187311261892319, 2.3035902976989746)\n",
      "COMET INFO:   Parameters [count]:\n",
      "COMET INFO:     C [2]           : 10\n",
      "COMET INFO:     batch_size      : 100\n",
      "COMET INFO:     hidden_size     : 128\n",
      "COMET INFO:     input_size      : 28\n",
      "COMET INFO:     kernel [4]      : rbf\n",
      "COMET INFO:     learning_rate   : 0.01\n",
      "COMET INFO:     num_classes     : 10\n",
      "COMET INFO:     num_epochs      : 2\n",
      "COMET INFO:     num_layers      : 2\n",
      "COMET INFO:     sequence_length : 28\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (48 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: old comet version (3.1.12) detected. current: 3.2.0 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/kondratevakate/sklearn-dummy-project/54e128abf5a24b248320601ef9daa649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "    \n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"kYVqzmHEUN7WQLo86k2bZs1Z7\",\n",
    "                        project_name=\"sklearn-dummy-project\", workspace=\"kondratevakate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "Shape of cancer data: (569, 30)\n",
      "\n",
      "Sample counts per class:\n",
      "{'malignant': 212, 'benign': 357}\n",
      "\n",
      "Feature names:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "random_state = 42\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): {}\".format(cancer.keys()))\n",
    "print(\"Shape of cancer data: {}\\n\".format(cancer.data.shape))\n",
    "print(\"Sample counts per class:\\n{}\".format(\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))\n",
    "print(\"\\nFeature names:\\n{}\".format(cancer.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "Confusion matrix \n",
      " [[52  1]\n",
      " [ 1 89]]\n",
      "F1 score is  0.989\n",
      "Precision score is  0.989\n",
      "Recall score is  0.989\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,\n",
    "    cancer.target,\n",
    "    stratify=cancer.target,\n",
    "    random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,5,10,20,50,100]}\n",
    "\n",
    "clf = GridSearchCV(logreg,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=10,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nResults\\nConfusion matrix \\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 score is {:6.3f}\".format(f1))\n",
    "print(\"Precision score is {:6.3f}\".format(precision))\n",
    "print(\"Recall score is {:6.3f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': [1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "for i in range(len(clf.cv_results_['params'])):\n",
    "    for k,v in clf.cv_results_.items():\n",
    "        if k == \"params\":\n",
    "            experiment.log_parameters(v[i])\n",
    "        else:\n",
    "            experiment.log_metric(k,v[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check this out: \n",
    "\n",
    "https://www.comet.ml/kondratevakate/sklearn-dummy-project/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/kondratevakate/sklearn-dummy-project/43a3ce31b60e45b6a969adc9f7911070\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     mean_fit_time [4]     : (0.0006013393402099609, 0.0035867691040039062)\n",
      "COMET INFO:     mean_score_time [4]   : (0.000199127197265625, 0.0012012481689453124)\n",
      "COMET INFO:     mean_test_score [4]   : (0.9666666666666666, 0.9800000000000001)\n",
      "COMET INFO:     param_C [4]           : (1, 10)\n",
      "COMET INFO:     param_kernel [4]      : rbf\n",
      "COMET INFO:     rank_test_score [4]   : (1, 4)\n",
      "COMET INFO:     split0_test_score [4] : (0.9666666666666667, 1.0)\n",
      "COMET INFO:     split1_test_score [4] : (0.9666666666666667, 1.0)\n",
      "COMET INFO:     split2_test_score [4] : (0.9, 0.9666666666666667)\n",
      "COMET INFO:     split3_test_score [4] : (0.9333333333333333, 0.9666666666666667)\n",
      "COMET INFO:     split4_test_score [4] : 1.0\n",
      "COMET INFO:     std_fit_time [4]      : (0.0004909964780239036, 0.0038183204729576896)\n",
      "COMET INFO:     std_score_time [4]    : (0.00039825439453125, 0.0007513325746068333)\n",
      "COMET INFO:     std_test_score [4]    : (0.016329931618554516, 0.038873012632301994)\n",
      "COMET INFO:   Parameters [count]:\n",
      "COMET INFO:     C [2]             : 10\n",
      "COMET INFO:     class_weight      : 1\n",
      "COMET INFO:     dual              : 1\n",
      "COMET INFO:     fit_intercept     : True\n",
      "COMET INFO:     intercept_scaling : 1\n",
      "COMET INFO:     kernel [4]        : rbf\n",
      "COMET INFO:     l1_ratio          : 1\n",
      "COMET INFO:     max_iter          : 100\n",
      "COMET INFO:     multi_class       : auto\n",
      "COMET INFO:     n_jobs            : 1\n",
      "COMET INFO:     penalty           : l2\n",
      "COMET INFO:     random_state      : 1\n",
      "COMET INFO:     solver            : lbfgs\n",
      "COMET INFO:     tol               : 0.0001\n",
      "COMET INFO:     verbose           : 1\n",
      "COMET INFO:     warm_start        : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (48 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: old comet version (3.1.12) detected. current: 3.2.0 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/kondratevakate/pytorch-dummy-project/7796b3978a114d51a799ad948c87421a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"kYVqzmHEUN7WQLo86k2bZs1Z7\",\n",
    "                        project_name=\"pytorch-dummy-project\", workspace=\"kondratevakate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.5517\n",
      "Epoch [1/2], Step [200/600], Loss: 0.2987\n",
      "Epoch [1/2], Step [300/600], Loss: 0.0777\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0827\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1044\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0601\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1374\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1368\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0716\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0857\n",
      "Epoch [2/2], Step [500/600], Loss: 0.3013\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0592\n",
      "Test Accuracy of the model on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "hyper_params = {\n",
    "    \"sequence_length\": 28,\n",
    "    \"input_size\": 28,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_size\": 50,\n",
    "    \"num_epochs\": 2,\n",
    "    \"learning_rate\": 0.01\n",
    "}\n",
    "\n",
    "experiment.log_parameters(hyper_params)\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=hyper_params['batch_size'],\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=hyper_params['batch_size'],\n",
    "                                          shuffle=False)\n",
    "\n",
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "rnn = RNN(hyper_params['input_size'], hyper_params['hidden_size'], hyper_params['num_layers'], hyper_params['num_classes'])\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=hyper_params['learning_rate'])\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "with experiment.train():\n",
    "    step = 0\n",
    "    for epoch in range(hyper_params['num_epochs']):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images.view(-1, hyper_params['sequence_length'], hyper_params['input_size']))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = rnn(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute train accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_total = labels.size(0)\n",
    "            total += batch_total\n",
    "\n",
    "            batch_correct = (predicted == labels.data).sum()\n",
    "            correct += batch_correct\n",
    "\n",
    "            # Log batch_accuracy to Comet.ml; step is each batch\n",
    "            step += 1\n",
    "            experiment.log_metric(\"batch_accuracy\", batch_correct / batch_total, step=step)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                      % (epoch + 1, hyper_params['num_epochs'], i + 1, len(train_dataset) // hyper_params['batch_size'], loss.item()))\n",
    "\n",
    "    # Log epoch accuracy to Comet.ml; step is each epoch\n",
    "        experiment.log_metric(\"batch_accuracy\", correct / total, step=epoch)\n",
    "\n",
    "\n",
    "with experiment.test():\n",
    "    # Test the Model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, hyper_params['sequence_length'], hyper_params['input_size']))\n",
    "        outputs = rnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    experiment.log_metric(\"accuracy\", correct / total)\n",
    "    print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tutorials adopted from: https://www.comet.ml/docs/python-sdk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
