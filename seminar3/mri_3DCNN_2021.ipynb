{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mri_3DCNN_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URuxAJkkEjV0"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1ZRkcOVQeo4iNvBqIWx5bepZ5vchXL6KN\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHS8qClIqSdl"
      },
      "source": [
        "## **MRI classification with 3D CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYI4bcYpptdM"
      },
      "source": [
        "#### 1. Introduction\n",
        "In this notebook we will explore simple 3D CNN classificationl model on `pytorch` from the Frontiers in Neuroscience paper: https://www.frontiersin.org/articles/10.3389/fnins.2019.00185/full. In the current notebook we follow [the paper](https://arxiv.org/pdf/2006.15969.pdf) on `3T` `T1w` MRI images from https://www.humanconnectome.org/. \n",
        "\n",
        "**Our goal will be to build a network for MEN and WOMEN brain classification, to explore gender influence on brain structure and find gender-specific biomarkers.**\n",
        "\n",
        "\n",
        "*Proceeding with this Notebook you confirm your personal acess [to the data](https://www.humanconnectome.org/study/hcp-young-adult/document/1200-subjects-data-release). \n",
        " And your agreement on data [terms and conditions](https://www.humanconnectome.org/study/hcp-young-adult/data-use-terms).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqAayt8wtZ-m"
      },
      "source": [
        "1. Importing needed libs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbVC-fIYcwoA"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as torch_data\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb4Hu77AuRte"
      },
      "source": [
        "2. Mounting Google Drive to Collab Notebook. You should go with the link and enter your personal authorization code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXYXRCCIB2Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c4c4e0-6357-4ba2-f294-61247c3be676"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IlGfuWsuot2"
      },
      "source": [
        "3. Get the data. Add a shortcut to your Google Drive for `labels.npy` and `tensors.npy`. \n",
        "\n",
        "Shared link: https://drive.google.com/drive/folders/1Cq35zfhqJHlmhQjNlsDIeQ71ZsT2aghv?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBxqm43mKUCl"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Skoltech Neuroimaging/NeuroML2020/data/seminars/anat/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tJhdbkMKte1"
      },
      "source": [
        "Let's watch the data. We will use `nilearn` package for the visualisation:  \n",
        "https://nilearn.github.io/modules/generated/nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRiEcgFIK5gZ"
      },
      "source": [
        "!pip  install --quiet --upgrade nilearn\n",
        "import nilearn\n",
        "from nilearn import plotting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsQ_-1WsMd0C"
      },
      "source": [
        "img = nilearn.image.load_img(data_dir +'100408.nii')\n",
        "plotting.plot_anat(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-yP8c-NanX"
      },
      "source": [
        "Questions:\n",
        "1. What is the size of image (file)?\n",
        "2. That is the intensity distribution of voxels?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHD0cZv9NmWg"
      },
      "source": [
        "img_array = nilearn.image.get_data(img)\n",
        "img_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMokM8qhKq_4"
      },
      "source": [
        "#### 2. Defining training and target samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1IcCer9NSG"
      },
      "source": [
        "X, y = np.load(data_dir + 'tensors.npy'), \\\n",
        "np.load(data_dir + 'labels.npy')\n",
        "X = X[:, np.newaxis, :, :, :]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-in4TXqOuzY"
      },
      "source": [
        "sample_data = X[1,0,:,:,:]\n",
        "X[1,0,:,:,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVv2Rd0GY5YZ"
      },
      "source": [
        "**From the sourse article:**\n",
        "\n",
        "[The original data were too large](https://www.frontiersin.org/articles/10.3389/fnins.2019.00185/full) to train the model and it would cause RESOURCE EXAUSTED problem while training due to the insufficient of GPU memory. The GPU we used in the experiment is NVIDIAN TITAN_XP with 12G memory each. To solve the problem, we scaled the size of FA image to [58 × 70 × 58]. This procedure may lead to a better classification result, since a smaller size of the input image can provide a larger receptive field to the CNN model. In order to perform the image scaling, “dipy” (http://nipy.org/dipy/) was used to read the .nii data of FA. Then “ndimage” in the SciPy (http://www.scipy.org) was used to reduce the size of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be_2ekP6PG2t"
      },
      "source": [
        "sample_img = nilearn.image.new_img_like(img, sample_data)\n",
        "plotting.plot_anat(sample_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ObKK2YQW2s"
      },
      "source": [
        "#### 3. Defining Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjalzY4ZylGC"
      },
      "source": [
        "class MriData(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(MriData, self).__init__()\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y).long()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lv4i-TSQvcX"
      },
      "source": [
        "#### 4. Defining the CNN model architecture\n",
        "\n",
        "[3D PCNN architecture](https://www.frontiersin.org/articles/10.3389/fnins.2019.00185/full)\n",
        "![model](https://www.frontiersin.org/files/Articles/442577/fnins-13-00185-HTML/image_m/fnins-13-00185-g001.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqFwgNpJHdDN"
      },
      "source": [
        "At first check if we have GPU onborad:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvbAGRRAHS63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc762caa-b68e-447b-c54e-cbbade48655b"
      },
      "source": [
        " torch.cuda.is_available()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX-W0Nv_HaLG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoEO3-oQxfV"
      },
      "source": [
        "## Hidden layers 1, 2 and 3\n",
        "hidden = lambda c_in, c_out: nn.Sequential(\n",
        "    nn.Conv3d(c_in, c_out, (3,3,3)), # Convolutional layer\n",
        "    nn.BatchNorm3d(c_out), # Batch Normalization layer\n",
        "    nn.ReLU(), # Activational layer\n",
        "    nn.MaxPool3d(2) # Pooling layer\n",
        ")\n",
        "\n",
        "class MriNet(nn.Module):\n",
        "    def __init__(self, c):\n",
        "        super(MriNet, self).__init__()\n",
        "        self.hidden1 = hidden(1, c)\n",
        "        self.hidden2 = hidden(c, 2*c)\n",
        "        self.hidden3 = hidden(2*c, 4*c)\n",
        "        self.linear = nn.Linear(128*5*7*5, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.hidden3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "c = 32\n",
        "model = MriNet(c).to(device)\n",
        "summary(model, (1, 58, 70, 58))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUtTLI4ZwhDi"
      },
      "source": [
        "#### 5. Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUZGw-ETwKA5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) \n",
        "#del X, y #deleting for freeing space on disc\n",
        "\n",
        "train_dataset = MriData(X_train, y_train)\n",
        "test_dataset = MriData(X_test, y_test)\n",
        "#del X_train, X_test, y_train, y_test #deleting for freeing space on disc"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BttsN8kG3YyG"
      },
      "source": [
        "train_dataset = MriData(X_train, y_train)\n",
        "test_dataset = MriData(X_test, y_test)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=45, shuffle=True)  #45 - recommended value for batchsize\n",
        "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=28, shuffle=False) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry5Deo3uYufS"
      },
      "source": [
        "CHECKPOINTS_DIR =  data_dir +'/checkpoints'\n",
        "\n",
        "criterion = nn.NLLLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InIC1EMOZRHs"
      },
      "source": [
        "# timing\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_accuracy(net, data_loader):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    for data, target in data_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        out = net(data)\n",
        "        pred = out.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "        del data, target\n",
        "    accuracy = 100. * correct / len(data_loader.dataset)\n",
        "    return accuracy.item()\n",
        "\n",
        "def get_loss(net, data_loader):\n",
        "    net.eval()\n",
        "    loss = 0 \n",
        "    for data, target in data_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        out = net(data)\n",
        "        loss += criterion(out, target).item()*len(data)\n",
        "\n",
        "        del data, target, out \n",
        "\n",
        "    return loss / len(data_loader.dataset)\n",
        "\n",
        "\n",
        "def train(epochs, net, criterion, optimizer, train_loader, val_loader, scheduler=None, verbose=True, save=False):\n",
        "    best_val_loss = 100_000\n",
        "    best_model = None\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "\n",
        "    train_loss_list.append(get_loss(net, train_loader))\n",
        "    val_loss_list.append(get_loss(net, val_loader))\n",
        "    train_acc_list.append(get_accuracy(net, train_loader))\n",
        "    val_acc_list.append(get_accuracy(net, val_loader))\n",
        "    if verbose:\n",
        "        print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(0, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
        "\n",
        "    net.to(device)\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "        net.train()\n",
        "        for X, y in train_loader:\n",
        "            # Perform one step of minibatch stochastic gradient descent\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = net(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            del X, y, out, loss #freeing gpu space\n",
        "            \n",
        "        \n",
        "        # define NN evaluation, i.e. turn off dropouts, batchnorms, etc.\n",
        "        net.eval()\n",
        "        for X, y in val_loader:\n",
        "            # Compute the validation loss\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            out = net(X)\n",
        "            del X, y, out #freeing gpu space\n",
        "         \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        \n",
        "        train_loss_list.append(get_loss(net, train_loader))\n",
        "        val_loss_list.append(get_loss(net, val_loader))\n",
        "        train_acc_list.append(get_accuracy(net, train_loader))\n",
        "        val_acc_list.append(get_accuracy(net, val_loader))\n",
        "\n",
        "        if save and val_loss_list[-1] < best_val_loss:\n",
        "            torch.save(net.state_dict(), CHECKPOINTS_DIR+'best_model')\n",
        "        freq = 1\n",
        "        if verbose and epoch%freq==0:\n",
        "            print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
        "        \n",
        "    return train_loss_list, val_loss_list, train_acc_list, val_acc_list    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UznBfFtRtQS"
      },
      "source": [
        "##### Training first **20 epochs**:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETQqxi4CeFgm"
      },
      "source": [
        "# training will take ~8 min\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "EPOCHS = 20\n",
        "\n",
        "train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgbxRc1RsPEl"
      },
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Loss history', fontsize=18)\n",
        "plt.plot(train_loss_list[1:], label='Train')\n",
        "plt.plot(val_loss_list[1:], label='Validation')\n",
        "plt.xlabel('# of epoch', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.legend(fontsize=16)\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Accuracy history', fontsize=18)\n",
        "plt.plot(train_acc_list, label='Train')\n",
        "plt.plot(val_acc_list, label='Validation')\n",
        "plt.xlabel('# of epoch', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.legend(fontsize=16)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT1c6OQmwvRV"
      },
      "source": [
        "##### K-Fold model validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sody3ciZTAcy"
      },
      "source": [
        "Questions:\n",
        "1. What is the purpose of K-Fold in that experiment setting?\n",
        "2. Can we afford cross-validation in regular DL?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwwuFwsH2Ifa"
      },
      "source": [
        "# execute for ~ 23 min\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "cross_vall_acc_list = []\n",
        "j = 0\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print('Doing {} split'.format(j))\n",
        "    j += 1\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    train_dataset = MriData(X_train, y_train)\n",
        "    test_dataset = MriData(X_test, y_test)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=45, shuffle=True)  #45 - recommended value for batchsize\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=28, shuffle=False) \n",
        "    \n",
        "    torch.manual_seed(1)\n",
        "    np.random.seed(1)\n",
        "\n",
        "    c = 32\n",
        "    model = MriNet(c).to(device)\n",
        "    criterion = nn.NLLLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)\n",
        "\n",
        "    train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=False, verbose=False) \n",
        "    cross_vall_acc_list.append(get_accuracy(model, val_loader))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKbs0w6HwynW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18d5c81-203c-4253-dcf7-288a905eec5a"
      },
      "source": [
        "print('Average cross-validation accuracy (3-folds):', sum(cross_vall_acc_list)/len(cross_vall_acc_list))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cross-validation accuracy (3-folds): 89.84725952148438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyL7fsSYdZBl",
        "outputId": "37f556af-a55a-46ac-b8a9-0e3b3c26bd78"
      },
      "source": [
        "cross_vall_acc_list"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86.52291107177734, 90.29649353027344, 92.72237396240234]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLX_sxmGsgI2"
      },
      "source": [
        "#### Model save\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSiiJhZZsf3u"
      },
      "source": [
        "# Training model on whole data and saving it\n",
        "dataset = MriData(X, y)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=45, shuffle=True)  #45 - recommended value for batchsize\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "model = MriNet(c).to(device)\n",
        "criterion = nn.NLLLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)\n",
        "\n",
        "train(EPOCHS, model, criterion, optimizer, loader, loader, scheduler=scheduler, save=True, verbose=False) \n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmw3OAG7Z9p4"
      },
      "source": [
        "## What else?\n",
        "\n",
        "MRI classifcation model interpretation \n",
        "\n",
        "Visit: https://github.com/kondratevakate/InterpretableNeuroDL\n",
        "\n",
        "Meaningfull perturbations on MEN brains prediction:\n",
        "\n",
        "![img](https://github.com/kondratevakate/InterpretableNeuroDL/blob/master/image/grad_cam.png?raw=true)"
      ]
    }
  ]
}